{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Survived'], axis=1)\n",
    "y=data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 24), (891,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female',\n",
       "       'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4',\n",
       "       'SibSp_5', 'SibSp_8', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3',\n",
       "       'Parch_4', 'Parch_5', 'Parch_6', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=MinMaxScaler()\n",
    "cols=train_x.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.152164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.371701  0.024350       0.0       0.0       1.0         1.0       0.0   \n",
       "1  0.334004  0.016908       0.0       0.0       1.0         0.0       1.0   \n",
       "2  0.396833  0.015127       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.786378  0.152164       1.0       0.0       0.0         1.0       0.0   \n",
       "4  0.334004  0.412821       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         0.0         1.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_scaled=scaler.fit_transform(train_x)\n",
    "train_x_scaled=pd.DataFrame(train_x_scaled, columns=cols)\n",
    "train_x_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448029</td>\n",
       "      <td>0.143462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405018</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415041</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390681</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.054164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.448029  0.143462       0.0       1.0       0.0         0.0       1.0   \n",
       "1  0.405018  0.129995       1.0       0.0       0.0         0.0       1.0   \n",
       "2  0.415041  0.014110       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.390681  0.025374       0.0       1.0       0.0         1.0       0.0   \n",
       "4  0.419355  0.054164       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      0.0      0.0      1.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_scaled=scaler.fit_transform(test_x)\n",
    "test_x_scaled=pd.DataFrame(test_x_scaled, columns=cols)\n",
    "test_x_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regrression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rita\\anaconda3.x\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions using prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict=logreg.predict(train_x)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f1_score  0.7514910536779325\n"
     ]
    }
   ],
   "source": [
    "k=f1_score(train_predict, train_y)\n",
    "print('Training f1_score ', k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict=logreg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions using predict_proba function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51884827, 0.48115173],\n",
       "       [0.90647373, 0.09352627],\n",
       "       [0.87283615, 0.12716385],\n",
       "       ...,\n",
       "       [0.22618576, 0.77381424],\n",
       "       [0.31341849, 0.68658151],\n",
       "       [0.04397024, 0.95602976]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict=logreg.predict_proba(train_x)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48115173, 0.09352627, 0.12716385, 0.77703743, 0.63126681,\n",
       "       0.11674452, 0.84483977, 0.77399077, 0.53424255, 0.08325748,\n",
       "       0.10615241, 0.08549416, 0.12428976, 0.09640596, 0.60870144,\n",
       "       0.08451352, 0.30785371, 0.12041591, 0.0716582 , 0.28607868,\n",
       "       0.10255469, 0.2186382 , 0.07119904, 0.58947538, 0.09035999,\n",
       "       0.51357816, 0.08534873, 0.55745849, 0.60332984, 0.12851603,\n",
       "       0.82056021, 0.08552892, 0.58637363, 0.13656129, 0.02225208,\n",
       "       0.57488763, 0.21833846, 0.12573663, 0.05864611, 0.2853249 ,\n",
       "       0.84165436, 0.39184328, 0.20302869, 0.70637996, 0.48033929,\n",
       "       0.94316312, 0.37063343, 0.2205554 , 0.16769734, 0.89280816,\n",
       "       0.13275356, 0.63973814, 0.238807  , 0.61024376, 0.34114053,\n",
       "       0.64675363, 0.77893922, 0.29266373, 0.10937281, 0.29886103,\n",
       "       0.5841017 , 0.29266373, 0.12456001, 0.45808028, 0.10276491,\n",
       "       0.97632956, 0.11715259, 0.08549416, 0.86390408, 0.6634102 ,\n",
       "       0.93088358, 0.74869853, 0.89820955, 0.44957807, 0.84194212,\n",
       "       0.24568529, 0.86541217, 0.5402822 , 0.55534189, 0.12851603,\n",
       "       0.52238782, 0.12802048, 0.13177326, 0.01884275, 0.68548386,\n",
       "       0.94700924, 0.67501104, 0.07560802, 0.27809775, 0.93191989,\n",
       "       0.29273272, 0.13656836, 0.09128033, 0.13656836, 0.20302869,\n",
       "       0.91201097, 0.34211657, 0.12429629, 0.55675025, 0.56727884,\n",
       "       0.13656836, 0.12437607, 0.09949905, 0.12804522, 0.125948  ,\n",
       "       0.0531187 , 0.30267903, 0.04187427, 0.74802636, 0.30269822,\n",
       "       0.238807  , 0.43320487, 0.1257353 , 0.13680929, 0.5400137 ,\n",
       "       0.33478828, 0.12430776, 0.92505078, 0.11316824, 0.13624236,\n",
       "       0.49570176, 0.46764953, 0.22478648, 0.40038695, 0.93479085,\n",
       "       0.33094946, 0.39079965, 0.61015518, 0.13655986, 0.67325816,\n",
       "       0.09013183, 0.09644469, 0.39191197, 0.90589219, 0.1257353 ,\n",
       "       0.02886737, 0.48208202, 0.06566387, 0.37890515, 0.90748345,\n",
       "       0.92860156, 0.13118134, 0.64224767, 0.10474306, 0.23324135,\n",
       "       0.25738044, 0.10958943, 0.92904806, 0.86364953, 0.9055551 ,\n",
       "       0.51352717, 0.46892359, 0.65731553, 0.07183578, 0.45349307,\n",
       "       0.08554301, 0.44676215, 0.27408427, 0.09256807, 0.80115141,\n",
       "       0.29579037, 0.27809775, 0.31593636, 0.66406429, 0.04636575,\n",
       "       0.25284025, 0.12045407, 0.82684009, 0.3460035 , 0.93782461,\n",
       "       0.05136818, 0.76125074, 0.61300299, 0.28465971, 0.32999277,\n",
       "       0.47655793, 0.50739161, 0.38113139, 0.08161062, 0.09035013,\n",
       "       0.08190444, 0.25573104, 0.04532726, 0.11551805, 0.92463837,\n",
       "       0.36860226, 0.93076146, 0.28380438, 0.26398616, 0.17003452,\n",
       "       0.14507643, 0.05690121, 0.57183061, 0.31900528, 0.12428192,\n",
       "       0.17186213, 0.29266373, 0.90055392, 0.63875791, 0.27133117,\n",
       "       0.44730658, 0.40498162, 0.61015518, 0.11313209, 0.21163147,\n",
       "       0.8900869 , 0.61905557, 0.08331794, 0.77345896, 0.13656836,\n",
       "       0.61170191, 0.61015518, 0.12573663, 0.15758972, 0.94468172,\n",
       "       0.08549416, 0.07425399, 0.90381521, 0.63053702, 0.13446337,\n",
       "       0.12053808, 0.31061169, 0.08552892, 0.88844273, 0.21493065,\n",
       "       0.16346681, 0.08549416, 0.72015758, 0.46365311, 0.13953966,\n",
       "       0.72258365, 0.46495729, 0.08699435, 0.25284025, 0.1689955 ,\n",
       "       0.73864247, 0.37423703, 0.87078605, 0.11293701, 0.03783055,\n",
       "       0.24899233, 0.0861567 , 0.21833846, 0.13236685, 0.64522947,\n",
       "       0.09640596, 0.66412635, 0.238807  , 0.53206282, 0.1173378 ,\n",
       "       0.92203936, 0.09709996, 0.66966523, 0.80602728, 0.95852407,\n",
       "       0.15350819, 0.37746695, 0.13284761, 0.08549416, 0.44922144,\n",
       "       0.04333097, 0.64691191, 0.08783275, 0.12455869, 0.92698862,\n",
       "       0.33022705, 0.56378076, 0.07931628, 0.08552892, 0.08546694,\n",
       "       0.7269438 , 0.13659528, 0.84342579, 0.66543996, 0.47840881,\n",
       "       0.27396898, 0.32991923, 0.07897326, 0.2947168 , 0.34144936,\n",
       "       0.06483598, 0.11674452, 0.61014372, 0.0875023 , 0.09816727,\n",
       "       0.44631691, 0.04812194, 0.85831302, 0.09331468, 0.82512798,\n",
       "       0.901088  , 0.55098889, 0.94162297, 0.09311469, 0.02952042,\n",
       "       0.94911271, 0.05677063, 0.31858715, 0.63811173, 0.11308871,\n",
       "       0.52902054, 0.42973727, 0.2436991 , 0.10681382, 0.12445457,\n",
       "       0.04175926, 0.06797531, 0.31012532, 0.09035999, 0.8017839 ,\n",
       "       0.61015518, 0.45234476, 0.0993442 , 0.238807  , 0.08713182,\n",
       "       0.1257353 , 0.11309472, 0.18939235, 0.11680273, 0.54901505,\n",
       "       0.35549171, 0.13193655, 0.81363442, 0.94673258, 0.44279676,\n",
       "       0.31858715, 0.58730844, 0.08541626, 0.13052071, 0.25274546,\n",
       "       0.12049097, 0.13656836, 0.02225208, 0.26097986, 0.08549416,\n",
       "       0.1665155 , 0.09710229, 0.23587507, 0.80687732, 0.05313683,\n",
       "       0.29117417, 0.93936888, 0.07704356, 0.06938719, 0.37228351,\n",
       "       0.41732232, 0.64105935, 0.0419142 , 0.19521237, 0.49361817,\n",
       "       0.34868767, 0.12872269, 0.80198814, 0.29472122, 0.46822425,\n",
       "       0.80013236, 0.06354953, 0.14920867, 0.12954491, 0.24659257,\n",
       "       0.89786749, 0.6484034 , 0.12851603, 0.27787356, 0.46695011,\n",
       "       0.80909999, 0.18380732, 0.08552892, 0.86631613, 0.96127053,\n",
       "       0.74697601, 0.93007095, 0.20521443, 0.66412635, 0.26376919,\n",
       "       0.4203979 , 0.38575546, 0.04568891, 0.74539464, 0.85575805,\n",
       "       0.12015009, 0.73291685, 0.46180623, 0.13656836, 0.13958664,\n",
       "       0.93584604, 0.238807  , 0.3193814 , 0.30174408, 0.58181404,\n",
       "       0.41184316, 0.35737388, 0.86348231, 0.0853628 , 0.08552892,\n",
       "       0.80909999, 0.65116241, 0.06692159, 0.11316824, 0.55777115,\n",
       "       0.75546909, 0.76748239, 0.9021532 , 0.5049279 , 0.12620739,\n",
       "       0.11644866, 0.39080736, 0.10203039, 0.88321838, 0.38571563,\n",
       "       0.11156185, 0.55534189, 0.25710506, 0.1165057 , 0.05678607,\n",
       "       0.46352339, 0.96539733, 0.92687329, 0.57480348, 0.85307997,\n",
       "       0.46442217, 0.60778016, 0.69217343, 0.24860574, 0.80578316,\n",
       "       0.17348655, 0.94233922, 0.10614103, 0.08501668, 0.06946168,\n",
       "       0.63478443, 0.85718359, 0.09083704, 0.06285211, 0.48855289,\n",
       "       0.61015518, 0.22567356, 0.1972392 , 0.58904975, 0.22949824,\n",
       "       0.18188986, 0.07928997, 0.65249376, 0.3230891 , 0.62395456,\n",
       "       0.70553749, 0.91866431, 0.83060421, 0.92990473, 0.77655142,\n",
       "       0.54254907, 0.12805215, 0.08549416, 0.08699435, 0.15397158,\n",
       "       0.54865817, 0.13656268, 0.09388649, 0.21992311, 0.4776182 ,\n",
       "       0.07183578, 0.07394662, 0.88116816, 0.9138182 , 0.96410303,\n",
       "       0.21110138, 0.14612102, 0.56838297, 0.26097986, 0.71267445,\n",
       "       0.74623923, 0.69398537, 0.91393761, 0.93307695, 0.08552892,\n",
       "       0.45731519, 0.79800219, 0.2371764 , 0.18380732, 0.61042083,\n",
       "       0.58390617, 0.61059737, 0.09013183, 0.24317617, 0.89464626,\n",
       "       0.14223912, 0.42793212, 0.39769999, 0.65488105, 0.08704974,\n",
       "       0.10948399, 0.15919761, 0.7209772 , 0.73018614, 0.40894564,\n",
       "       0.89815788, 0.57113988, 0.22400163, 0.07928997, 0.07928997,\n",
       "       0.07927507, 0.44676215, 0.11588435, 0.87389843, 0.08193696,\n",
       "       0.06498396, 0.86415687, 0.26199659, 0.04183959, 0.12057118,\n",
       "       0.6353921 , 0.13656836, 0.92789856, 0.32561218, 0.25284025,\n",
       "       0.13236685, 0.10940791, 0.08346057, 0.11809979, 0.27809775,\n",
       "       0.41378924, 0.75705407, 0.02225208, 0.52357839, 0.94798001,\n",
       "       0.34532225, 0.12323865, 0.8940885 , 0.48032776, 0.22618016,\n",
       "       0.40280769, 0.73184847, 0.12118765, 0.03717055, 0.02225208,\n",
       "       0.08549416, 0.52252502, 0.08452186, 0.08743903, 0.04290345,\n",
       "       0.93153541, 0.06800489, 0.60056482, 0.88116374, 0.35832736,\n",
       "       0.47105268, 0.75430686, 0.55050448, 0.09637563, 0.08534873,\n",
       "       0.08546694, 0.08549416, 0.20639229, 0.6101466 , 0.12573663,\n",
       "       0.58731137, 0.12660733, 0.09710229, 0.10999913, 0.74557128,\n",
       "       0.93313787, 0.45314713, 0.32151506, 0.18380732, 0.88631693,\n",
       "       0.24437679, 0.50974388, 0.69577988, 0.89822471, 0.72707726,\n",
       "       0.04982928, 0.61020948, 0.06404639, 0.61015518, 0.18161526,\n",
       "       0.38678795, 0.0858564 , 0.17749297, 0.11915639, 0.69406843,\n",
       "       0.07938208, 0.11334556, 0.94014175, 0.2388585 , 0.21833846,\n",
       "       0.05694259, 0.88034063, 0.04123783, 0.38776922, 0.39885074,\n",
       "       0.71854667, 0.84251957, 0.08534873, 0.44637033, 0.82259995,\n",
       "       0.89556507, 0.12340646, 0.03587997, 0.04385266, 0.03306758,\n",
       "       0.61015518, 0.12573663, 0.72015758, 0.05313683, 0.85361644,\n",
       "       0.6557252 , 0.10258607, 0.04943368, 0.11375361, 0.21483287,\n",
       "       0.41043168, 0.10784448, 0.61839302, 0.14872025, 0.97367632,\n",
       "       0.78009088, 0.04890664, 0.14486938, 0.13922405, 0.66412635,\n",
       "       0.08465766, 0.61007234, 0.22722952, 0.13656836, 0.48387577,\n",
       "       0.87138652, 0.19660174, 0.94433244, 0.77903223, 0.22618016,\n",
       "       0.15008443, 0.06097986, 0.12573663, 0.10285175, 0.05496285,\n",
       "       0.08132742, 0.26398616, 0.68106622, 0.58554817, 0.71853694,\n",
       "       0.10958943, 0.13656411, 0.08549416, 0.93655131, 0.32999277,\n",
       "       0.1099004 , 0.74411224, 0.94772069, 0.31934179, 0.65140626,\n",
       "       0.51629181, 0.14039788, 0.94468172, 0.94262855, 0.69048186,\n",
       "       0.1172346 , 0.94833553, 0.72587357, 0.08552892, 0.25334958,\n",
       "       0.70327585, 0.3708683 , 0.48029058, 0.2436991 , 0.62611323,\n",
       "       0.77381424, 0.68658151, 0.95602976])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds=train_predict[:,1]\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train_preds)):\n",
    "    if(train_preds[i]>0.55):\n",
    "        train_preds[i]=1\n",
    "    else:\n",
    "        train_preds[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f1_score  0.7366255144032922\n"
     ]
    }
   ],
   "source": [
    "k=f1_score(train_preds, train_y)\n",
    "print('Training f1_score ' , k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_predict=logreg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       144\n",
      "           1       0.77      0.71      0.74        79\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.81      0.80      0.80       223\n",
      "weighted avg       0.82      0.82      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf=confusion_matrix(test_y, test_predict)\n",
    "from sklearn.metrics import classification_report as rep\n",
    "print(rep(test_y, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       144\n",
      "           1       0.77      0.71      0.74        79\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.81      0.80      0.80       223\n",
      "weighted avg       0.82      0.82      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rep(test_y, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03571759,  0.00288254,  1.0192484 ,  0.15031021, -1.08315422,\n",
       "         1.18922918, -1.10282479,  0.85217536,  1.06360854,  0.35348416,\n",
       "        -0.67875648, -0.78989884, -0.28656203, -0.42764634,  0.12495485,\n",
       "         0.59959848, -0.18582475,  0.21238851, -0.35432165, -0.14200592,\n",
       "        -0.16838514,  0.14182262,  0.23542417, -0.2908424 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-d69d3b75f9e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Variables'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_reshape'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 960x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6), dpi=120, facecolor='w', edgecolor='b')\n",
    "x=range(len(train_x.columns))\n",
    "c=logreg.coef_reshape(-1)\n",
    "plt.bar(x,c)\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Coefficient plot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficient plot')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6), dpi=120, facecolor='w', edgecolor='b')\n",
    "x=range(len(train_x.columns))\n",
    "c=logreg.coef_.reshape(-1)\n",
    "plt.bar(x,c)\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Coefficient plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.035718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.002883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.019248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.150310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>1.083154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable  coefficients\n",
       "0       Age      0.035718\n",
       "1      Fare      0.002883\n",
       "2  Pclass_1      1.019248\n",
       "3  Pclass_2      0.150310\n",
       "4  Pclass_3      1.083154"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Coefficients=pd.DataFrame({'Variable' : train_x.columns, 'coefficients' : abs(c)})\n",
    "Coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the variables with high coefficients only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Coefficients.Coefficients>0.3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3.x\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Coefficients.Coefficients>0.3'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-aee1828b43ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msig_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCoefficients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Coefficients.Coefficients>0.3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3.x\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.x\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Coefficients.Coefficients>0.3'"
     ]
    }
   ],
   "source": [
    "sig_var=Coefficients['Coefficients.Coefficients>0.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
